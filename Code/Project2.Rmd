---
title: "ST 558 Project 2"
author: "John Hinic & Fang Wu"
date: '2022-07-01'
params:
  filter_type: bus
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.path = "../images")
library(readr)
library(dplyr)
library(ggplot2)
library(caret)
library(corrplot)
#install.packages("devtools")
#library(devtools)
#install_github("AppliedDataSciencePartners/xgboostExplainer")
```

## Introduction 

The consumption of online news is expediting day by day due to the extensive adoption of smartphones and the rise of social networks. Online news can capture the eye of a signiﬁcant amount of Internet users within a brief period of your time. Prediction of online news popularity helps news organizations to gain better insights into the audience interests and to deliver more relevant and appealing content in a proactive manner. The company can allocate resources more wisely to prepare stories over their life cycle. Moreover, prediction of news popularity is also beneﬁcial for trend forecasting, understanding the collective human behavior, advertisers to propose more proﬁtable monetization techniques,and readers to ﬁlter the huge amount of information quickly and efﬁciently.

We are going to analyze and predict the number of shares within different data channel of interest using an online news data set from [Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity#) . This data set summarizes a heterogeneous set of features about articles published by Mashable in a period of two years.

* We are going to focus on the following predictors:

  1. url: URL of the article (non-predictive)
  
  2. timedelta: Days between the article publication and the dataset acquisition (non-predictive)
  
  3. n_tokens_title: Number of words in the title

  4. n_tokens_content Number of words in the content

  5. n_unique_tokens: Rate of unique words in the content

  6. n_non_stop_unique_tokens: Rate of unique non-stop words in the content

  7. num_hrefs: Number of links

  8. num_self_hrefs: Number of links to other articles published by Mashable

  9. num_imgs: Number of images

  10. num_videos: Number of videos

  11. average_token_length: Average length of the words in the content

  12. num_keywords: Number of keywords in the metadata

  13. self_reference_min_shares: Min. shares of referenced articles in Mashable

  14. self_reference_max_shares: Max. shares of referenced articles in Mashable

  15. self_reference_avg_sharess: Avg. shares of referenced articles in Mashable

  16. global_subjectivity: Text subjectivity

  17. global_sentiment_polarity: Text sentiment polarity

  18. global_rate_positive_words: Rate of positive words in the content

  19. global_rate_negative_words: Rate of negative words in the content

  20. rate_positive_words: Rate of positive words among non-neutral tokens

  21. rate_negative_words: Rate of negative words among non-neutral tokens

  22. title_subjectivity: Title subjectivity

  23. title_sentiment_polarity: Title polarity

  24. abs_title_subjectivity: Absolute subjectivity level

  25. abs_title_sentiment_polarity: Absolute polarity level

  26. shares: Number of shares (target)

Stop Words usually refer to the most common words in a language, there is no single universal list of stop words used by all natural language processing tools. For some search engines, these are some of the most common, short function words, such as the, is, at, which, and on.

In order to predict the number of share, we are going to build linear regression and ensemble tree-based model.

## Prepare Data

We'll use the `readr` and `dplyr` packages from `tifyverse`. First, we are going to read in data as tibble using function `read_csv`. Next, in order to access different data channel of interest automatically, we are going to create a variable called `type`. Last we `filter` the data channel of interest using `params$` automatically.  

* Read in raw data and create new variable `type`

```{r}
# read in raw data
raw_data <- read_csv("../Data/OnlineNewsPopularity.csv") 

# create type column for different data channel
type_data <- raw_data %>% mutate(type=ifelse(data_channel_is_lifestyle==1, "lifestyle", ifelse(data_channel_is_entertainment==1, "entertainment", ifelse(data_channel_is_bus==1, "bus", ifelse(data_channel_is_socmed==1, "socmed", ifelse(data_channel_is_tech==1, "tech", ifelse(data_channel_is_world==1, "world", NA)))))))
```

* Subset data channel of interest automatically with `params`

```{r}
# select data for data channel of interest
target_data <- type_data %>% filter(type == params$filter_type) 
target_data
```

* Split data into train and test sets

```{r}
set.seed(100)
train_index <- createDataPartition(target_data$is_weekend, p=0.7, list=FALSE)
train <- target_data[train_index,]
test <- target_data[-train_index, ]
dim(train)
```

## Summarizations on train set

* descriptive statistics on numeric variables:

```{r}
summary(train %>% select(timedelta, n_tokens_title, n_tokens_content, n_unique_tokens, n_non_stop_unique_tokens, num_hrefs, num_self_hrefs, num_imgs, num_videos, average_token_length, num_keywords, self_reference_avg_sharess, self_reference_min_shares, self_reference_max_shares, global_rate_negative_words, global_rate_positive_words, global_sentiment_polarity, global_subjectivity, rate_negative_words, rate_positive_words, title_subjectivity, title_sentiment_polarity, abs_title_sentiment_polarity, abs_title_subjectivity))
```

We can find the minimum, 25% percentile, mean, median, 75% percentile and maximum values of each numeric variables from this chart. 

```{r}
sapply(train %>% select(timedelta, n_tokens_title, n_tokens_content, n_unique_tokens, n_non_stop_unique_tokens, num_hrefs, num_self_hrefs, num_imgs, num_videos, average_token_length, num_keywords, self_reference_avg_sharess, self_reference_min_shares, self_reference_max_shares, global_rate_negative_words, global_rate_positive_words, global_sentiment_polarity, global_subjectivity, rate_negative_words, rate_positive_words, title_subjectivity, title_sentiment_polarity, abs_title_sentiment_polarity, abs_title_subjectivity), sd)
```

From here we can compare standard deviation between numeric variables.

* Correlation between numeric variables

```{r}
#str(train)
Correlation <- cor(train %>% select(-url, -type, -starts_with("weekday"), -starts_with("data_channel"), -is_weekend ))
corrplot(Correlation, type="upper", tl.pos="lt", cl.cex=0.8)
```

This plot help us to check linear relationship between numeric variables. We want to avoid include predictors with high correlation in the same model. 

* summary across different day of the week

We are going to create a new variable named `weekday` and visualize share performance on different day of the week.

```{r}
# create predictor weekday 
train <- train %>% mutate(weekday=ifelse(weekday_is_monday==1, "Monday", ifelse(weekday_is_tuesday==1, "Tuesday", ifelse(weekday_is_wednesday==1, "Wednesday", ifelse(weekday_is_thursday==1, "Thursday", ifelse(weekday_is_friday==1, "Friday", ifelse(weekday_is_saturday==1, "Saturday", ifelse(weekday_is_sunday==1, "Sunday", NA))))))))

test <- test %>% mutate(weekday=ifelse(weekday_is_monday==1, "Monday", ifelse(weekday_is_tuesday==1, "Tuesday", ifelse(weekday_is_wednesday==1, "Wednesday", ifelse(weekday_is_thursday==1, "Thursday", ifelse(weekday_is_friday==1, "Friday", ifelse(weekday_is_saturday==1, "Saturday", ifelse(weekday_is_sunday==1, "Sunday", NA))))))))

# shares on different day
train %>% group_by(weekday) %>% summarize(n=n(), min=min(shares), max=max(shares), avg=mean(shares), median=median(shares))
```

We can inspect the effect of `weekday` on the `share`. The number of records on each day as well as the minimum, maximum, mean and median values of shares on each day of the week are included in the table here. If there are big difference across `weekday`, then `weekday` and `share` are dependent. 

We also can check the difference in plot.

```{r}
g <- ggplot(train %>% filter(shares<quantile(shares, p=0.75)), aes(x=shares))
g + geom_freqpoly(aes(color=weekday)) +
  ggtitle("Counts of shares across day of the week")
```

```{r}
ggplot(train, aes(x=weekday, y=shares)) +
  geom_boxplot() +
  scale_y_continuous(limits=c(min(train$shares), quantile(train$shares, p=0.75)+IQR(train$shares))) +
  ggtitle("box plot of shares across day of the week")
```

In this plot, we can compare the median, 25% percentile, 75% percentile and IQR of shares between different day of the week. It will show the effect of day on the shares.

* Scatter plot

We want to check the relationship between response variable `share` and other predictors through scatter plot. Linear or non-linear? Positive or negative?

```{r}
g <- ggplot(train, aes(x=num_self_hrefs, y=shares) )
g + geom_jitter() +
    scale_y_continuous(limits=c(min(train$shares), quantile(train$shares, p=0.75)+2*IQR(train$shares))) +
    scale_x_continuous(limits=c(min(train$num_self_hrefs), quantile(train$num_self_hrefs, p=0.75)+2*IQR(train$num_self_hrefs))) +
    ggtitle("scatter plot of shares against number of links") 
```

```{r}
g <- ggplot(train, aes(x=rate_positive_words, y=shares) )
g + geom_point() +
  scale_y_continuous(limits=c(min(train$shares), quantile(train$shares, p=0.75)+2*IQR(train$shares))) +
  ggtitle("scatter plot of shares against rate of positive words")
```

## Modeling

We will be fitting 4 total models for comparison:

- 2 linear regression models
- 1 random forest model
- 1 boosted tree model

For all 4 models, we will use 10-fold cross-validation to select the best fit.

```{r}
control <- trainControl(method="cv", number=10)
```


### Linear Regression

-----REGRESSION EXPLANATION PLACEHOLDER-----

#### Fang

```{r}
mlFit <- train(shares~timedelta+weekday+num_self_hrefs+num_imgs+num_videos, data=train, method="lm", preProcess=c("center", "scale"), trControl=control)
mlFit
```

#### John

```{r John regression cache = TRUE}
mlFit2 <- train(
  shares ~ .,
  data = train %>% select(-url, -timedelta, -starts_with("data_channel"), -starts_with("weekday"), -type, -is_weekend, -rate_negative_words),
  method = "lmStepAIC",
  preProcess = c("center", "scale"),
  trControl = control,
  trace = FALSE,
  scope = list(upper = ~., lower = ~1)
)
mlFit2
```

### Tree-based model

* Boosted Trees

Boosted trees model trains a bunch of trees sequentially. Each subsequent tree learns from the mistakes of the previous tree. So predictions get updated as trees grown. It is used for both regression and classification. 

```{r, results=FALSE}
n.trees=c(50, 100, 150)
interaction.depth=c(2,3,4)
shrinkage=c(0.1, 0.5)
n.minobsinnode=c(10)
tune_parameter <- expand.grid(n.trees=n.trees, interaction.depth=interaction.depth, shrinkage=shrinkage, n.minobsinnode=n.minobsinnode)
boostedFit <- train(shares~timedelta+weekday+num_self_hrefs+num_imgs+num_videos+rate_positive_words, data=train, method="gbm", trControl=trainControl(method="repeatedcv", number=5, repeats=3), tuneGrid=tune_parameter)
boostedFit
```

### Compare models on the test set

```{r}
ml_pred <- predict(mlFit, test)
ml_MSE <- postResample(test$shares, ml_pred)[1]
boosted_pred <- predict(boostedFit, test)
boosted_MSE <- postResample(test$shares, boosted_pred)[1]
comp <- data.frame(LR=ml_MSE, Boosted=boosted_MSE)
comp
```

```{r}
best_model <- which.min(comp["RMSE",])
best_model
```

`r names(best_model)` has the minimum MSE which indicates the best fitting. 



